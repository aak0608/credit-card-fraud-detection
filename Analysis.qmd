---
title: "Credit card fraud detection"
format: html
editor: visual
---


# Introduction

Credit card fraud is a growing concern in the financial industry, causing significant losses for banks and customers alike. With the rise of online transactions and digital payments, fraudsters have become increasingly sophisticated in exploiting security vulnerabilities. Detecting fraudulent transactions is a challenging task due to the highly imbalanced nature of fraud datasets, where fraudulent transactions represent only a small fraction of total transactions.

The dataset used in this analysis is derived from real-world credit card transactions and contains anonymized features extracted using Principal Component Analysis (PCA). The goal is to build predictive models that can accurately distinguish between fraudulent and legitimate transactions, helping financial institutions prevent financial losses and enhance security measures.


```{r echo=FALSE, warning=FALSE, message=FALSE}
# Load necessary libraries
library(tidyverse)
library(data.table)
library(ggplot2)
library(caret)
library(ROSE)
library(PRROC)
library(xgboost)
library(gridExtra)
library(patchwork)
library(DT)
library(kableExtra)
library(randomForest)
```

# Reading the data

```{r echo=FALSE, warning=FALSE, message=FALSE}
## Load Dataset
data <- fread("data/creditcard.csv")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
data %>% head() %>% DT::datatable()
```

# About the data

## Columns in the Credit Card Fraud Detection Dataset

| Column Name | Description |
|-------------|-------------|
| Time        | Seconds elapsed between this transaction and the first transaction in the dataset. |
| V1 to V28   | Anonymized features resulting from a PCA transformation. |
| Amount      | The transaction amount. |
| Class       | Target variable (0 for legitimate transactions, 1 for fraudulent transactions). |

:::{.callout-note}

The data has the dimensions of `r dim(data)`.

### Dataset and Its Significance
The dataset used in this analysis consists of anonymized credit card transactions, where each row represents a single transaction. Due to privacy concerns, the dataset does not include personally identifiable information but instead provides 28 principal components (V1 to V28) obtained using PCA. The dataset also includes the transaction amount and a binary label (`Class`), where:
- `0` represents a legitimate (non-fraudulent) transaction.
- `1` represents a fraudulent transaction.

Detecting fraudulent transactions is particularly challenging because fraud cases are rare. The class imbalance means that naive models may predict most transactions as non-fraudulent and still achieve high accuracy, making it essential to use alternative evaluation metrics such as precision, recall, and the F1-score. 

By exploring this dataset, we aim to uncover key patterns that distinguish fraudulent transactions from legitimate ones, aiding in the development of more robust fraud detection systems. Fraudulent transactions often exhibit distinct characteristics, such as unusual spending behavior, high transaction amounts, or rapid consecutive transactions from different locations. Understanding these patterns allows financial institutions to implement real-time fraud detection systems that minimize false positives while effectively identifying fraudulent activities.

Additionally, credit card fraud detection relies heavily on machine learning algorithms due to the vast amount of transaction data generated every second. By leveraging supervised learning models and data preprocessing techniques such as PCA transformation and oversampling methods, we can enhance the detection of fraudulent activities. The findings from this study can help improve financial security measures and refine existing fraud detection systems by identifying high-risk transactions efficiently.


:::

## Exploring the data

```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(data) %>% DT::datatable() # Summary statistics
```


### Check Class Imbalance

```{r echo=FALSE, warning=FALSE, message=FALSE}


new_table <- table(data$Class)

kable(new_table, format = "html", table.attr = "class='table'") %>% 
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"), position = "center") %>%
  column_spec(1, border_right = TRUE) %>%  # Add a line between columns
  row_spec(0, bold = TRUE, color = "white", background = "lightblue")

```

### Visualizing Class Distribution

```{r echo=FALSE, warning=FALSE, message=FALSE}

ggplot(data, aes(x = factor(Class), fill = factor(Class))) +
  geom_bar(color = "black", size = 0.5) +
  scale_fill_manual(values = c("#0073C2FF", "#EFC000FF")) +
  theme_minimal() +
  labs(title = "Class Distribution of Transactions", x = "Class (0: Non-Fraud, 1: Fraud)", y = "Count") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
        axis.title = element_text(face = "bold"),
        legend.position = "none") +
  scale_y_continuous(labels = scales::comma)
```
:::{.callout-note}

__Observation for Class Distribution Graph__

The bar graph visually represents the distribution of fraudulent and non-fraudulent transactions in the dataset.

- Severe Class Imbalance:

1. The graph shows that the vast majority of transactions belong to the non-fraudulent class (0), while fraudulent transactions (1) make up a tiny fraction of the dataset.

2. This extreme imbalance is a common challenge in fraud detection, as models may become biased toward predicting the majority class, leading to poor recall for fraud cases.

- Impact on Model Performance:

1. Since fraud transactions are rare, a na√Øve model that predicts all transactions as non-fraudulent would still achieve high accuracy.

2. However, accuracy alone is misleading in this scenario, as the model would fail to correctly identify fraud cases, which is the primary objective of fraud detection.

- Need for Resampling Techniques:

Due to this imbalance, techniques such as oversampling, undersampling, or synthetic data generation (e.g., SMOTE or ROSE) are necessary to balance the dataset and improve model learning.

:::

### PCA Scatter Plot

```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(data, aes(x = V1, y = V2, color = as.factor(Class))) +
  geom_point(alpha = 0.5, size = 1.5) +
  scale_color_manual(values = c("#0073C2FF", "#EFC000FF")) +
  theme_minimal() +
  labs(title = "PCA Components: V1 vs V2", x = "Principal Component 1 (V1)", y = "Principal Component 2 (V2)", color = "Class") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  geom_density_2d(color = "black", alpha = 0.3)

```

:::{.callout-note}

1. Fraudulent transactions (Class 1) are concentrated in distinct regions of the PCA-transformed space.

2. Non-fraudulent transactions (Class 0) are more dispersed, indicating greater variation in their feature distribution.

3. The clustering of fraudulent transactions suggests that certain PCA components can be useful in fraud detection.

:::

### Density Plot for Amount

```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(data, aes(x = Amount, fill = as.factor(Class))) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = c("#0073C2FF", "#EFC000FF")) +
  theme_minimal() +
  labs(title = "Density Distribution of Transaction Amounts", x = "Transaction Amount", y = "Density", fill = "Class") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```


```{r echo=FALSE, warning=FALSE, message=FALSE}

data$Amount_Category <- cut(data$Amount, 
                            breaks = quantile(data$Amount, probs = seq(0, 1, by = 0.25), na.rm = TRUE), 
                            labels = c("Low", "Medium", "High", "Very High"), 
                            include.lowest = TRUE)

ggplot(data, aes(x = Amount, fill = factor(Class))) +
  geom_density(alpha = 0.5, adjust = 1.5) +
  scale_fill_manual(values = c("#0073C2FF", "#EFC000FF")) +
  facet_wrap(~Amount_Category, scales = "free") +
  theme_classic() +
  labs(title = "Density of Transaction Amount by Fraud Class", 
       x = "Transaction Amount", 
       y = "Density",
       fill = "Class (0: Non-Fraud, 1: Fraud)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
        axis.title = element_text(face = "bold"))


```

:::{.callout-note}

Based on the density plots, some of the interesting observations are:

__Fraudulent Transactions Show Distinct Density Distributions__

Fraudulent transactions (Class 1) exhibit different density peaks compared to legitimate transactions (Class 0). The density for fraud cases is generally lower, but it is concentrated in specific transaction amount ranges.

__Fraud Occurrence Increases with Higher Transaction Amounts__

As we move to the "High" and "Very High" transaction amount categories, fraudulent transactions appear more frequently.This suggests that fraudsters often target higher-value transactions, possibly to maximize their financial gain.

__Legitimate Transactions Are More Evenly Distributed__

The density of legitimate transactions remains relatively high across all amount categories, indicating that customers make a wide range of purchases. Unlike fraudulent transactions, they do not exhibit sharp density spikes in specific ranges.

__Overlapping Distributions in Lower Amount Categories__

In the "Low" and "Medium" amount bins, there is significant overlap between fraudulent and legitimate transactions, making fraud detection more challenging in this range. This suggests that lower-value fraudulent transactions may be harder to differentiate from normal purchases.

__Potential for Threshold-Based Fraud Detection__

Given the differences in density, setting different risk thresholds based on transaction amount could improve fraud detection accuracy. Higher-value transactions might need stricter anomaly detection rules compared to low-value ones.

:::


### Boxplot to detect anomalies

```{r echo=FALSE, warning=FALSE, message=FALSE}

ggplot(data, aes(x = factor(Class), y = Amount, fill = factor(Class))) +
  geom_boxplot(outlier.colour = "red", outlier.shape = 16) +
  labs(title = "Transaction Amounts by Class", x = "Class", y = "Amount") +
  theme_minimal()
```

## Data Preprocessing

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Normalize Amount
scaler <- preProcess(data[, .(Amount)], method = "range")
data$Amount <- predict(scaler, data[, .(Amount)])

# Remove Time column
data <- data[, -c("Time")]

data %>% head() %>% DT::datatable()
```

1. We first normalise the amount then remove `Time` column.

2. In this analysis, the ROSE (Random Over-Sampling Examples) method was applied to generate a more balanced training set.
Practical Implications for Fraud Detection:

3. In real-world applications, fraud detection models must prioritize high recall and precision, ensuring fraudulent transactions are flagged without overwhelming users with false positives.

Banks and financial institutions must use sophisticated models such as XGBoost or Random Forest, which can handle imbalanced data more effectively than traditional logistic regression.

we apply all 3 to discuss which works best for this dataset.

```{r echo=FALSE, warning=FALSE, message=FALSE}
## Splitting Data
set.seed(123)
index <- createDataPartition(data$Class, p = 0.8, list = FALSE)
train_data <- data[index, ]
test_data <- data[-index, ]

## Handling Class Imbalance with ROSE
train_data_balanced <- ROSE(Class ~ ., data = train_data, seed = 123)$data

bal_table <- table(train_data_balanced$Class)  # Checking new balance

kable(bal_table, format = "html", table.attr = "class='table'") %>% 
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"), position = "center") %>%
  column_spec(1, border_right = TRUE) %>%  # Add a line between columns
  row_spec(0, bold = TRUE, color = "white", background = "lightblue")
```

# Model Training

```{r echo=FALSE, warning=FALSE, message=FALSE}
str(train_data_balanced$Class)  # Should show "Factor w/ 2 levels"

```


## Logistic Regression
```{r echo=FALSE, warning=FALSE, message=FALSE}
## Model Training & Comparison
logistic_model <- glm(Class ~ ., data = train_data_balanced, family = binomial)
logistic_preds <- predict(logistic_model, test_data, type = "response")
logistic_class <- ifelse(logistic_preds > 0.5, 1, 0)
logistic_cm <- confusionMatrix(factor(logistic_class), factor(test_data$Class))
logistic_pr <- pr.curve(scores.class0 = logistic_preds, weights.class0 = test_data$Class, curve = TRUE)

print(logistic_cm)
```

### Logistic Regression Precision-Recall Curve
```{r echo=FALSE, warning=FALSE, message=FALSE}
# PR Curves
plot(logistic_pr, main = "Logistic Regression Precision-Recall Curve")
```

## Random Forest

```{r echo=FALSE, warning=FALSE, message=FALSE}
train_data_balanced$Class <- as.factor(train_data_balanced$Class)
rf_model <- randomForest(Class ~ ., data = train_data_balanced, ntree = 100)
rf_preds <- predict(rf_model, test_data, type = "prob")[,2]
rf_class <- ifelse(rf_preds > 0.5, 1, 0)
rf_cm <- confusionMatrix(factor(rf_class), factor(test_data$Class))
rf_pr <- pr.curve(scores.class0 = rf_preds, weights.class0 = test_data$Class, curve = TRUE)
rf_importance <- varImp(rf_model)

print(rf_cm)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
plot(rf_pr, main = "Random Forest Precision-Recall Curve")
```


## XGBoost

```{r echo=FALSE, warning=FALSE, message=FALSE}
## Splitting Data
set.seed(123)
index <- createDataPartition(data$Class, p = 0.8, list = FALSE)
train_data <- data[index, ]
test_data <- data[-index, ]

## Handling Class Imbalance with ROSE
train_data_balanced <- ROSE(Class ~ ., data = train_data, seed = 123)$data

table(train_data_balanced$Class)  # Checking new balance
```

### Model Training and Evaluation

```{r echo=FALSE, warning=FALSE, message=FALSE}
## Model Training - XGBoost
set.seed(123)

# Ensure all features are numeric
train_data_balanced[] <- lapply(train_data_balanced, function(x) as.numeric(as.character(x)))
test_data[] <- lapply(test_data, function(x) as.numeric(as.character(x)))

train_matrix <- xgb.DMatrix(data = as.matrix(train_data_balanced[, !names(train_data_balanced) %in% "Class"]), 
                            label = train_data_balanced$Class)

test_matrix <- xgb.DMatrix(data = as.matrix(test_data[, -"Class", with = FALSE]), 
                           label = test_data$Class)

params <- list(
  objective = "binary:logistic",
  eval_metric = "aucpr",
  max_depth = 6,
  eta = 0.1
)

model <- xgb.train(params = params, data = train_matrix, nrounds = 100)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
## Predictions
preds <- predict(model, test_matrix)
preds_class <- ifelse(preds > 0.5, 1, 0)
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
## Evaluation
conf_matrix <- confusionMatrix(factor(preds_class), factor(test_data$Class))
auprc <- pr.curve(scores.class0 = preds, weights.class0 = test_data$Class, curve = TRUE)

print(conf_matrix)
```

### Area Under the Precision-Recall Curve

```{r echo=FALSE, warning=FALSE, message=FALSE}
plot(auprc)
```


# Discussion of Results

- Logistic Regression performs moderately well but struggles with imbalanced data.
- Random Forest improves performance by capturing complex interactions.
- XGBoost delivers the highest precision-recall score, making it the most effective for fraud detection.


