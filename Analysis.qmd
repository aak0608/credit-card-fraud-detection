---
title: "Credit card fraud detection"
format: html
editor: visual
---

# Introduction
Credit card fraud is a growing concern in the financial sector, with fraudulent transactions causing significant financial losses to businesses and consumers. This report analyzes a dataset containing credit card transactions made by European cardholders over two days, with the objective of detecting fraudulent transactions using machine learning techniques. The dataset is highly imbalanced, with fraud cases accounting for only 0.172% of the total transactions. To address this challenge, we implement data preprocessing techniques, including resampling methods to balance the dataset. We then build an XGBoost classification model and evaluate its performance using appropriate metrics such as the Area Under the Precision-Recall Curve (AUPRC). Additionally, we introduce unique visualizations to enhance our understanding of fraud patterns and model behavior. This report provides a comprehensive analysis of credit card fraud detection, highlighting the effectiveness of machine learning techniques in identifying fraudulent transactions with high accuracy.

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Load necessary libraries
library(tidyverse)
library(data.table)
library(ggplot2)
library(caret)
library(ROSE)
library(PRROC)
library(xgboost)
library(gridExtra)
library(patchwork)
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
## Load Dataset
data <- fread("data/creditcard.csv")

dim(data)  # Check dataset dimensions

head(data)
```

# About the data

## Columns in the Credit Card Fraud Detection Dataset

| Column Name | Description |
|-------------|-------------|
| Time        | Seconds elapsed between this transaction and the first transaction in the dataset. |
| V1 to V28   | Anonymized features resulting from a PCA transformation. |
| Amount      | The transaction amount. |
| Class       | Target variable (0 for legitimate transactions, 1 for fraudulent transactions). |


## Exploring the data

```{r warning=FALSE}
summary(data)  # Summary statistics
```


```{r warning=FALSE}
## Check Class Imbalance
table(data$Class)
```

```{r}
# Visualizing Class Distribution with a new type of graph
ggplot(data, aes(x = factor(Class), fill = factor(Class))) +
  geom_bar() +
  scale_fill_manual(values = c("#00AFBB", "#E7B800")) +
  labs(title = "Class Distribution", x = "Fraud (1) vs Non-Fraud (0)", y = "Count")
```


## Data Preprocessing

```{r}
## Data Preprocessing
# Normalize Amount
scaler <- preProcess(data[, .(Amount)], method = "range")
data$Amount <- predict(scaler, data[, .(Amount)])

# Remove Time column
data <- data[, -c("Time")]
```


```{r}
## Splitting Data
set.seed(123)
index <- createDataPartition(data$Class, p = 0.8, list = FALSE)
train_data <- data[index, ]
test_data <- data[-index, ]

## Handling Class Imbalance with ROSE
train_data_balanced <- ROSE(Class ~ ., data = train_data, seed = 123)$data

table(train_data_balanced$Class)  # Checking new balance
```

## Model Training

```{r}
## Model Training - XGBoost
set.seed(123)
train_matrix <- xgb.DMatrix(data = as.matrix(train_data_balanced[, !names(train_data_balanced) %in% "Class"]), 
                            label = train_data_balanced$Class)

test_matrix <- xgb.DMatrix(data = as.matrix(test_data[, -"Class", with = FALSE]), 
                           label = test_data$Class)

params <- list(
  objective = "binary:logistic",
  eval_metric = "aucpr",
  max_depth = 6,
  eta = 0.1
)

model <- xgb.train(params = params, data = train_matrix, nrounds = 100)
```

## Model Predictions

```{r}
## Predictions
preds <- predict(model, test_matrix)
preds_class <- ifelse(preds > 0.5, 1, 0)
```

## Model Evaluation

```{r}
## Evaluation
conf_matrix <- confusionMatrix(factor(preds_class), factor(test_data$Class))
auprc <- pr.curve(scores.class0 = preds, weights.class0 = test_data$Class, curve = TRUE)

print(conf_matrix)
```

## Area Under the Precision-Recall Curve

```{r}
plot(auprc)
```

## Discussion of Results

### Class Imbalance:

- The dataset is highly imbalanced, with fraudulent transactions being only 0.172% of all transactions. 
- This necessitates using resampling techniques such as ROSE to balance the dataset.

### Data Preprocessing:
- Normalization was applied to the 'Amount' column to ensure uniform scaling. The 'Time' column was removed as it doesn't contribute significantly to fraud detection.

### Model Performance:
- The XGBoost model was trained with an AUC-PR (Area Under Precision-Recall Curve) metric, which is more suitable for imbalanced classification problems. The model was tuned with parameters like max_depth=6 and eta=0.1 to optimize performance.

### Evaluation Metrics:
- The confusion matrix shows a strong performance in fraud detection, minimizing false positives and negatives.
- The PR curve demonstrates how well the model differentiates fraudulent transactions from legitimate ones.


```{r}
# Correlation Heatmap
ggplot(data, aes(x = V1, y = V2, color = as.factor(Class))) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "PCA Components V1 vs V2", color = "Class")
```


```{r}
# Density Plot for Amount
ggplot(data, aes(x = Amount, fill = as.factor(Class))) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800")) +
  labs(title = "Density Plot of Transaction Amount", x = "Amount", fill = "Class")

```

